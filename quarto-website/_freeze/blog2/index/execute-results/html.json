{
  "hash": "f6b9e33665cbb4f5afcb5ef26da067c0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Models for prediction of enzymmatic indicators of liver damage with various biologic, demographic, and psychosocial predictors\"\nauthor: \"Landon Power\"\ndate: last-modified\nformat: \n  html:\n    editor: visual\n    toc: true\n    toc_float: true\n    number-sections: true\n    embed-resources: true\n    date-format: iso\n    theme: paper\n---\n\n\n\n\n# Setup and Data Ingest\n\n## Setup\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(janitor)\nlibrary(knitr)\nlibrary(magrittr)\nlibrary(broom)\nlibrary(naniar)\nlibrary(patchwork)\nlibrary(modelsummary)\nlibrary(pwr)\nlibrary(haven) # Package to ingest SAS transport files for 2017-2020 Pre-pandemic NHANES data\nlibrary(forcats) # Package for rearranging categorical variables\nlibrary(car) # For Box-Cox plot and transformations\nlibrary(equatiomatic) # For linear model equation extraction\nlibrary(Hmisc)\nlibrary(tidyverse)\n\nsource(\"data/Love-boost.R\")\n\ntheme_set(theme_light())  # or use theme_set(theme_bw())\nknitr::opts_chunk$set(comment=NA)\n```\n:::\n\n\n\n\n## Data Ingest\n\nFor this project, I will be using a similar data set to what I used in Study 1, but will be expanding the data set to include other possible predictors of liver enzyme outcomes.\n\nI ingested the demographic raw data from the NHANES 2017-2020 Pre-Pandemic Demographic data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initially save the data from the NHANES Pre-pandemic 2017-2020 SAS transport\n#demographic <- haven::read_xpt(\"data/P_DEMO.xpt\")\n\n#saveRDS(demographic, \"data/P_DEMO.Rds\")\n\n# Simply read the tibble after data are saved\ndemographic <- readRDS(\"data/P_DEMO.Rds\")\n```\n:::\n\n\n\n\nI ingested the standard biochemistry panel raw data from the NHANES 2017-2020 Pre-Pandemic Laboratory data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initially save the data from the NHANES Pre-pandemic 2017-2020 SAS transport\n#biochem <- haven::read_xpt(\"data/P_BIOPRO.xpt\")\n\n#saveRDS(biochem, \"data/P_BIOPRO.Rds\")\n\n# Simply read the tibble after data are saved\nbiochem <- readRDS(\"data/P_BIOPRO.Rds\")\n```\n:::\n\n\n\n\nFinally, I ingested the Alcohol Use raw data from the NHANES 2017-2020 Pre-Pandemic Questionnaire data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Initially save the data from the NHANES Pre-pandemic 2017-2020 SAS transport\n#alcohol <- haven::read_xpt(\"data/P_ALQ.xpt\")\n\n#saveRDS(alcohol, \"data/P_ALQ.Rds\")\n\n# Simply read the tibble after data are saved\nalcohol <- readRDS(\"data/P_ALQ.Rds\")\n```\n:::\n\n\n\n\n# Cleaning the Data\n\n## Cleaning\n\nI then merged the NHANES files before cleaning and selecting my variables.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_uncleaned1 <- left_join(demographic, biochem, by = \"SEQN\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfull_uncleaned2 <- left_join(full_uncleaned1, alcohol, by = \"SEQN\")\n```\n:::\n\n\n\n\nThen I cleaned the variables and selected only the variables I will use in analysis. I first cleaned the names of all the variables in the `full_uncleaned2` dataset.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfull <- full_uncleaned2 %>%\n  clean_names() %>%\n  mutate(across(where(is_character), as_factor))\n```\n:::\n\n\n\n\nI then selected the variables I will analyze and refined the observations to include only subjects who:\n\n-   had a `ridstatr` value of 2, meaning they were both interviewed and examined (N = 14,300)\n\n-   had a `ridageyr` between 21 and 79 years old (N = 7,853)\n\nFor my analysis, I then filtered to the proper variables I will include in my analytic tibble:\n\n-   seqn, ridstatr\n\n-   outcome variable: lbxsatsi\n\n-   key predictor: alq121, which I recoded to to be a categorical variable with 6 categories\n\n    -   I excluded the participants that responded as \"Refused\" or \"Don't Know\" since this will be the key predictor and also filtered to the complete cases for this predictor.\n\n-   Age: ridageyr\n\n-   Sex: I recoded the `riagendr` variable to sex.\n\n-   Race/Ethnicity: ridreth3\n\n-   Education status: dmdeduce2, which I recoded to be a 4-level categorical variable\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nliver_damage <- full %>%\n  filter(ridstatr == \"2\") %>%\n  filter(between(ridageyr, 21, 79)) %>%\n  select(seqn, ridstatr, lbxsatsi, alq121, ridageyr, \n         riagendr, ridreth3, dmdeduc2) %>%\n  mutate(alq121 = fct_recode(factor(alq121), \n                            \"Never\" = \"0\", \n                            \"Nearly Every Day\" = \"1\",\n                            \"Nearly Every Day\" = \"2\",\n                            \"2-4 times/week\" = \"3\",\n                            \"2-4 times/week\" = \"4\",\n                            \"2-4 times/month\" = \"5\",\n                            \"2-4 times/month\" = \"6\",\n                            \"7-12 times/year\" = \"7\",\n                            \"7-12 times/year\" = \"8\",\n                            \"1-6 times/year\" = \"9\",\n                            \"1-6 times/year\" = \"10\")) %>%\n  mutate(sex = fct_recode(factor(riagendr), \n                            \"male\" = \"1\", \n                            \"female\" = \"2\")) %>%\n  mutate(ridreth3 = fct_recode(factor(ridreth3), \n                            \"Hispanic/LatinX\" = \"1\", \n                            \"Hispanic/LatinX\" = \"2\",\n                            \"Non-Hispanic White\" = \"3\",\n                            \"Non-Hispanic Black\" = \"4\",\n                            \"Non-Hispanic Asian\" = \"6\",\n                            \"Other Race/Multiracial\" = \"7\")) %>%\n  mutate(dmdeduc2 = fct_recode(factor(dmdeduc2),\n                                \"Less than HS\" = \"1\",\n                                \"Less than HS\" = \"2\",\n                                \"HS Grad\" = \"3\",\n                                \"Some College\" = \"4\",\n                                \"College Grad\" = \"5\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nliver_damage <- liver_damage %>%\n  select(seqn, ridstatr, lbxsatsi, alq121, ridageyr, \n         sex, ridreth3, dmdeduc2) %>%\n  filter(alq121 != \"77\") %>%\n  filter(alq121 != \"99\") %>%\n  droplevels(liver_damage$alq121) %>%\n  filter(complete.cases(lbxsatsi, alq121))\n\nhead(liver_damage)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 8\n    seqn ridstatr lbxsatsi alq121         ridageyr sex    ridreth3      dmdeduc2\n   <dbl>    <dbl>    <dbl> <fct>             <dbl> <fct>  <fct>         <fct>   \n1 109266        2       15 1-6 times/year       29 female Non-Hispanic… College…\n2 109271        2        8 Never                49 male   Non-Hispanic… Less th…\n3 109273        2       35 Never                36 male   Non-Hispanic… Some Co…\n4 109274        2       19 2-4 times/week       68 male   Other Race/M… Some Co…\n5 109282        2       17 Never                76 male   Non-Hispanic… College…\n6 109290        2       19 Never                68 female Non-Hispanic… College…\n```\n\n\n:::\n:::\n\n\n\n\n## Imputation\n\nAfter filtering the outcome and key predictor to complete cases, I then determined whether there were missing values in the other variables.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngg_miss_var(liver_damage)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\nAfter exclusion of any missing values for alanine aminotransferase levels (ALT, the outcome variable) and alcohol consumption (alq121, the key predictor), there were no missing values in any of the other variables, so an imputation process was not necessary.\n\n# Codebook and Data Description\n\n| Variable | Type | Description |\n|:----------------------:|:----------------------:|:----------------------:|\n| SEQN | ID | Respondent sequence number |\n| ridstatr | ID | Interview/Examination status, all completed follow up |\n| **Outcome:** lbxsatsi | Quant | Alanine aminotransferase (ALT; in U/L) |\n| **Key Predictor:** alq151 | 6-Cat | Past 12 mo how often drink alcoholic bev |\n| ridageyr | Quant | Age |\n| sex | Binary | Sex, male or female |\n| ridreth3 | 5-Cat | Race/Ethnicity |\n| dmdeduc2 | 4-Cat | Education level for adults 20+ |\n\n## Analytic Tibble\n\nThe complete tibble and a summary of the variables that are missing values is shown below.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nliver_damage\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6,254 × 8\n     seqn ridstatr lbxsatsi alq121          ridageyr sex    ridreth3    dmdeduc2\n    <dbl>    <dbl>    <dbl> <fct>              <dbl> <fct>  <fct>       <fct>   \n 1 109266        2       15 1-6 times/year        29 female Non-Hispan… College…\n 2 109271        2        8 Never                 49 male   Non-Hispan… Less th…\n 3 109273        2       35 Never                 36 male   Non-Hispan… Some Co…\n 4 109274        2       19 2-4 times/week        68 male   Other Race… Some Co…\n 5 109282        2       17 Never                 76 male   Non-Hispan… College…\n 6 109290        2       19 Never                 68 female Non-Hispan… College…\n 7 109292        2       21 2-4 times/week        58 male   Hispanic/L… HS Grad \n 8 109293        2       19 Never                 44 male   Non-Hispan… HS Grad \n 9 109297        2       17 2-4 times/month       30 female Non-Hispan… Some Co…\n10 109298        2       22 Never                 68 male   Non-Hispan… Less th…\n# ℹ 6,244 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngg_miss_var(liver_damage)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmiss_var_summary(liver_damage)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 8 × 3\n  variable n_miss pct_miss\n  <chr>     <int>    <num>\n1 seqn          0        0\n2 ridstatr      0        0\n3 lbxsatsi      0        0\n4 alq121        0        0\n5 ridageyr      0        0\n6 sex           0        0\n7 ridreth3      0        0\n8 dmdeduc2      0        0\n```\n\n\n:::\n:::\n\n\n\n\n## Data Summary\n\n### Outcome: Alanine aminotransferase (ALT; in U/L)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndescribe(liver_damage$lbxsatsi)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nliver_damage$lbxsatsi : Alanine Aminotransferase (ALT) (U/L) \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n    6254        0      140    0.999    22.77    14.93        9       10 \n     .25      .50      .75      .90      .95 \n      13       18       26       39       51 \n\nlowest :   3   4   5   6   7, highest: 208 211 213 338 682\n```\n\n\n:::\n:::\n\n\n\n\nBased on this numerical summary of the data, it appears that there is one outlier that has a ALT level that is double that of all the other subjects. For the integrity of the data analysis, this observation will be removed. Therefore, there will only be 6253 subjects for analysis.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nliver_damage <- liver_damage %>%\n  filter(lbxsatsi < 400)\n```\n:::\n\n\n\n\n### Key Predictor: Alcohol consumption\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndescribe(liver_damage$alq121)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nliver_damage$alq121 \n       n  missing distinct \n    6253        0        6 \n                                                                              \nValue                 Never Nearly Every Day   2-4 times/week  2-4 times/month\nFrequency              1302              427              976             1361\nProportion            0.208            0.068            0.156            0.218\n                                            \nValue       7-12 times/year   1-6 times/year\nFrequency               884             1303\nProportion            0.141            0.208\n```\n\n\n:::\n:::\n\n\n\n\n### Age (in years)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndescribe(liver_damage$ridageyr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nliver_damage$ridageyr : Age in years at screening \n       n  missing distinct     Info     Mean      Gmd      .05      .10 \n    6253        0       59        1    49.27    18.39       24       27 \n     .25      .50      .75      .90      .95 \n      36       50       62       70       74 \n\nlowest : 21 22 23 24 25, highest: 75 76 77 78 79\n```\n\n\n:::\n:::\n\n\n\n\n### Sex (male or female)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndescribe(liver_damage$sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nliver_damage$sex \n       n  missing distinct \n    6253        0        2 \n                        \nValue        male female\nFrequency    3165   3088\nProportion  0.506  0.494\n```\n\n\n:::\n:::\n\n\n\n\n### Race/Ethnicity\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndescribe(liver_damage$ridreth3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nliver_damage$ridreth3 \n       n  missing distinct \n    6253        0        5 \n                                                                               \nValue             Hispanic/LatinX     Non-Hispanic White     Non-Hispanic Black\nFrequency                    1462                   2204                   1660\nProportion                  0.234                  0.352                  0.265\n                                                        \nValue          Non-Hispanic Asian Other Race/Multiracial\nFrequency                     598                    329\nProportion                  0.096                  0.053\n```\n\n\n:::\n:::\n\n\n\n\n### Education level\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndescribe(liver_damage$dmdeduc2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nliver_damage$dmdeduc2 \n       n  missing distinct \n    6253        0        6 \n                                                                           \nValue      Less than HS      HS Grad Some College College Grad            7\nFrequency          1022         1497         2155         1574            1\nProportion        0.163        0.239        0.345        0.252        0.000\n                       \nValue                 9\nFrequency             4\nProportion        0.001\n```\n\n\n:::\n:::\n\n\n\n\n# Research Question\n\nFrom my previous analysis in Study 1, I determined that alcohol consumption may be a variable of interest that may be associated with alanine aminotransferase (ALT) levels. In this analysis, I wanted to determine whether or not ALT levels can be predicted by another measure of alcohol consumption, the frequency of drinking over the past year. To explore this relationship, I will analyze multiple variables from the NHANES 2017-2020 dataset. There were 6254 NHANES participants with both complete ALT values and alcohol consumption data.\n\n**Question:** As elevated ALT is a well-known indicator of liver damage, and my previous study showed that ALT may be associated with variables like alcohol consumption in the NHANES data set, can the frequency of alcohol consumption over the past year be used as an appropriate model for ALT outcomes in the 6254 participants from the NHANES data set?\n\n**Expectation:** I expect that alcohol consumption will be a good model for ALT outcomes, however, I do think that other variables, such as age and sex may account for increased ALT in certain subsets of the NHANES participants. Therefore, I think that frequency of alcohol consumption alone will model ALT outcomes, but a multivariate model that includes other cofactors may be a more appropriate model for ALT values.\n\n# Partitioning the Data\n\nTo construct models of the data, I first split the data set into two different subsets, including a training and test sample. The training sample includes 70% of the data and the test sample includes 30% of the data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2024)\n\ntraining_data <- liver_damage |> slice_sample(prop = 0.70)\n\ntest_data <- \n    anti_join(liver_damage, training_data, by = \"seqn\")\n\nnrow(training_data); nrow(test_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4377\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1876\n```\n\n\n:::\n:::\n\n\n\n\nAfter partitioning, there were 4377 observations in the training data set and 1877 observations in the test data set. This adds up to the total of 6254 observations that were in the initial, un-partitioned data set.\n\n# Transformation and Outcome\n\n## Visualization of Training Data\n\nIn order to determine the skew of the data and whether a transformation is necessary, I constructed three plots to visualize the training data and compare it to a normal distribution. Based on the strong right-handed skew of the outcome variable, ALT levels, I will consider a transformation of the data using a Box-Cox plot.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(training_data, aes(x = lbxsatsi)) +\n    geom_histogram(bins = 12, col = \"white\", fill = \"dodgerblue\")\n\np2 <- ggplot(training_data, aes(x = lbxsatsi, y = \"\")) +\n    geom_violin() + \n    geom_boxplot(fill = \"dodgerblue\", width = 0.3) +\n    labs(y = \"\")\n\np3 <- ggplot(training_data, aes(sample = lbxsatsi)) +\n    geom_qq(col = \"dodgerblue\") + geom_qq_line() + \n    labs(y = \"Observed ALT (in U/L)\", x = \"Normal (0,1) expectation\")\n\n(p1 / p2 + plot_layout(heights = c(2,1))) | p3 \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n\n\n## Transformation\n\nTo determine which transformation I should use, I constructed a Box-Cox plot. To construct the Box-Cox, I first had to build a linear model with the training data. I built the linear model using only the key predictor variable.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel0 <- lm(lbxsatsi ~ alq121, data = training_data)\n\nboxCox(model0)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\n\nAfter determining that a transformation was necessary with the initial visualization, I calculated a Power Transformation summary on the training set data for the initial linear model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(powerTransform(model0))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nbcPower Transformation to Normality \n   Est Power Rounded Pwr Wald Lwr Bnd Wald Upr Bnd\nY1   -0.3449       -0.33      -0.3892      -0.3006\n\nLikelihood ratio test that transformation parameter is equal to 0\n (log transformation)\n                           LRT df       pval\nLR test, lambda = (0) 245.4018  1 < 2.22e-16\n\nLikelihood ratio test that no transformation is needed\n                           LRT df       pval\nLR test, lambda = (1) 4427.301  1 < 2.22e-16\n```\n\n\n:::\n:::\n\n\n\n\nBased on the power transformation summary, it appears that I need to transform the ALT data by taking the inverse and square rooting the ALT values. This transformation makes sense because there is a very long right-handed tail in the data set with high values that are multiple orders of magnitude greater than the smaller values. The inverse square root power transformation also helps to reduce the variance and decreases the impact of extreme values on the variable distribution.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntraining_data <- training_data %>%\n  mutate(sqrinv_alt = (1/(sqrt(lbxsatsi))))\n```\n:::\n\n\n\n\nI then re-visualized the training data using the transformed ALT values.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(training_data, aes(x = sqrinv_alt)) +\n    geom_histogram(bins = 12, col = \"white\", fill = \"salmon2\")\n\np2 <- ggplot(training_data, aes(x = sqrinv_alt, y = \"\")) +\n    geom_violin() + \n    geom_boxplot(fill = \"salmon2\", width = 0.3) +\n    labs(y = \"\")\n\np3 <- ggplot(training_data, aes(sample = sqrinv_alt)) +\n    geom_qq(col = \"salmon2\") + geom_qq_line() + \n    labs(y = \"Observed sqrinv(ALT) (ALT in U/L)\", x = \"Normal (0,1) expectation\")\n\n(p1 / p2 + plot_layout(heights = c(2,1))) | p3 \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\n\nThe inverse square root transformation greatly improved the distribution of the data and made it conform much more closely to the normality assumptions. However, this transformation would be very difficult to interpret when applying it to the model. Instead of using the recommended inverse square root transformation by the Box-Cox plot, I decided to use an inverse transformation to help control the right-skewness of the data and decrease the impact of the very large ALT values. This inversely transformed data will be what I use for linear modeling.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntraining_data <- training_data %>%\n  mutate(inv_alt = (1/(lbxsatsi)))\n```\n:::\n\n\n\n\nAfter re-calculating the transformation, I visualized the inverse transformation fo the ALT data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot(training_data, aes(x = inv_alt)) +\n    geom_histogram(bins = 12, col = \"white\", fill = \"seagreen3\")\n\np2 <- ggplot(training_data, aes(x = inv_alt, y = \"\")) +\n    geom_violin() + \n    geom_boxplot(fill = \"seagreen3\", width = 0.3) +\n    labs(y = \"\")\n\np3 <- ggplot(training_data, aes(sample = inv_alt)) +\n    geom_qq(col = \"seagreen3\") + geom_qq_line() + \n    labs(y = \"Observed 1/(ALT) (ALT in U/L)\", x = \"Normal (0,1) expectation\")\n\n(p1 / p2 + plot_layout(heights = c(2,1))) | p3 \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n\n\n# The Big Model\n\n## Linear model for all candidate predictors\n\nI constructed the first linear model with all the possible predictors, including the key predictor, frequency of alcohol consumption, and all the secondary predictors: age, sex, race/ethnicity, and education level.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- lm(inv_alt ~ alq121 + ridageyr + sex + ridreth3 + dmdeduc2, \n             data = training_data)\n```\n:::\n\n\n\n\n## Model equation\n\nI then summarized the model equation for the overall model with all five predictors from the model summary.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_eq(model1, use_coefs = TRUE, coef_digits = 3)\n```\n\n::: {.cell-output-display}\n$$\n\\operatorname{\\widehat{inv\\_alt}} = 0.053 - 0.007(\\operatorname{alq121}_{\\operatorname{Nearly\\ Every\\ Day}}) - 0.006(\\operatorname{alq121}_{\\operatorname{2-4\\ times/week}}) - 0.005(\\operatorname{alq121}_{\\operatorname{2-4\\ times/month}}) - 0.004(\\operatorname{alq121}_{\\operatorname{7-12\\ times/year}}) - 0.004(\\operatorname{alq121}_{\\operatorname{1-6\\ times/year}}) + 0(\\operatorname{ridageyr}) + 0.019(\\operatorname{sex}_{\\operatorname{female}}) + 0.007(\\operatorname{ridreth3}_{\\operatorname{Non-Hispanic\\ White}}) + 0.015(\\operatorname{ridreth3}_{\\operatorname{Non-Hispanic\\ Black}}) + 0.004(\\operatorname{ridreth3}_{\\operatorname{Non-Hispanic\\ Asian}}) + 0.008(\\operatorname{ridreth3}_{\\operatorname{Other\\ Race/Multiracial}}) - 0.002(\\operatorname{dmdeduc2}_{\\operatorname{HS\\ Grad}}) - 0.003(\\operatorname{dmdeduc2}_{\\operatorname{Some\\ College}}) - 0.002(\\operatorname{dmdeduc2}_{\\operatorname{College\\ Grad}}) - 0.015(\\operatorname{dmdeduc2}_{\\operatorname{7}}) + 0.006(\\operatorname{dmdeduc2}_{\\operatorname{9}})\n$$\n\n:::\n:::\n\n\n\n\n## Coefficients Tidy Summary\n\nAfter summarizing the equation for the large linear model, I created a tidy summary of the model coefficients.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(model1, conf.int = TRUE, conf.level = 0.90) %>%\n  select(term, estimate, std.error, conf.low, conf.high) %>%\n  knitr::kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term                           | estimate| std.error| conf.low| conf.high|\n|:------------------------------|--------:|---------:|--------:|---------:|\n|(Intercept)                    |    0.053|     0.002|    0.049|     0.057|\n|alq121Nearly Every Day         |   -0.007|     0.002|   -0.010|    -0.004|\n|alq1212-4 times/week           |   -0.006|     0.001|   -0.009|    -0.004|\n|alq1212-4 times/month          |   -0.005|     0.001|   -0.007|    -0.003|\n|alq1217-12 times/year          |   -0.004|     0.001|   -0.007|    -0.002|\n|alq1211-6 times/year           |   -0.004|     0.001|   -0.006|    -0.001|\n|ridageyr                       |    0.000|     0.000|    0.000|     0.000|\n|sexfemale                      |    0.019|     0.001|    0.017|     0.020|\n|ridreth3Non-Hispanic White     |    0.007|     0.001|    0.005|     0.009|\n|ridreth3Non-Hispanic Black     |    0.015|     0.001|    0.013|     0.017|\n|ridreth3Non-Hispanic Asian     |    0.004|     0.002|    0.001|     0.007|\n|ridreth3Other Race/Multiracial |    0.008|     0.002|    0.004|     0.011|\n|dmdeduc2HS Grad                |   -0.002|     0.001|   -0.005|     0.000|\n|dmdeduc2Some College           |   -0.003|     0.001|   -0.005|    -0.001|\n|dmdeduc2College Grad           |   -0.002|     0.001|   -0.005|     0.000|\n|dmdeduc27                      |   -0.015|     0.028|   -0.061|     0.032|\n|dmdeduc29                      |    0.006|     0.014|   -0.017|     0.029|\n\n\n:::\n:::\n\n\n\n\nFrom the summary of the coefficients, it appears that multiple of the variables demonstrate 90% confidence intervals that do not include 0 and therefore may be significantly associated with the trends in 1/ALT outcomes.\n\n# Small Model\n\n## Linear model for all candidate predictors\n\nNow, I have constructed the smaller model with only the naive key predictor, frequency of alcohol consumption, and have eliminated all the secondary predictors: age, sex, race/ethnicity, and education level.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- lm(inv_alt ~ alq121, \n             data = training_data)\n```\n:::\n\n\n\n\n## Model equation\n\nI then summarized the model equation for the smaller model with all five predictors from the model summary.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_eq(model2, use_coefs = TRUE, coef_digits = 3)\n```\n\n::: {.cell-output-display}\n$$\n\\operatorname{\\widehat{inv\\_alt}} = 0.064 - 0.01(\\operatorname{alq121}_{\\operatorname{Nearly\\ Every\\ Day}}) - 0.008(\\operatorname{alq121}_{\\operatorname{2-4\\ times/week}}) - 0.005(\\operatorname{alq121}_{\\operatorname{2-4\\ times/month}}) - 0.004(\\operatorname{alq121}_{\\operatorname{7-12\\ times/year}}) - 0.002(\\operatorname{alq121}_{\\operatorname{1-6\\ times/year}})\n$$\n\n:::\n:::\n\n\n\n\n## Coefficients Tidy Summary\n\nAfter summarizing the equation for the smaller linear model, I created a tidy summary of the model coefficients.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(model2, conf.int = TRUE, conf.level = 0.90) %>%\n  select(term, estimate, std.error, conf.low, conf.high) %>%\n  knitr::kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term                   | estimate| std.error| conf.low| conf.high|\n|:----------------------|--------:|---------:|--------:|---------:|\n|(Intercept)            |    0.064|     0.001|    0.062|     0.065|\n|alq121Nearly Every Day |   -0.010|     0.002|   -0.014|    -0.007|\n|alq1212-4 times/week   |   -0.008|     0.002|   -0.011|    -0.006|\n|alq1212-4 times/month  |   -0.005|     0.001|   -0.007|    -0.003|\n|alq1217-12 times/year  |   -0.004|     0.002|   -0.006|    -0.001|\n|alq1211-6 times/year   |   -0.002|     0.001|   -0.004|     0.000|\n\n\n:::\n:::\n\n\n\n\nFrom the summary of the coefficients, it appears that all of the categories of the alcohol consumption frequency variable, except for participants who drank only 1 to 6 times a year, demonstrate 90% confidence intervals that do not include 0 and therefore may be significantly associated with the trends in 1/ALT outcomes.\n\n# In-Sample Comparison\n\n## Quality of Fit\n\nIn this section, I extract the R-squared, adjusted R-squared, AIC, and BIC values to assess the fit of each of the two models.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng1 <- glance(model1) %>% mutate(model = \"Large Model (5 predictors)\")  \ng2 <- glance(model2) %>% mutate(model = \"Small Model (Key predictor\") \ncomp <- bind_rows(g1, g2) \n\ncomp %>% select(model, r.squared, adj.r.squared, AIC, BIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  model                      r.squared adj.r.squared     AIC     BIC\n  <chr>                          <dbl>         <dbl>   <dbl>   <dbl>\n1 Large Model (5 predictors)    0.140        0.136   -18854. -18739.\n2 Small Model (Key predictor    0.0111       0.00993 -18266. -18222.\n```\n\n\n:::\n:::\n\n\n\n\n## Posterior Predictive Checks\n\nFor posterior predictive checks, I first constructed an ideal model with the same number of predictors and observations as the large model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2024)\n\nx1 <- rnorm(6253, 20, 5)\nx2 <- rnorm(6253, 20, 12)\nx3 <- rnorm(6253, 20, 10)\nx4 <- rnorm(6253, 20, 15)\nx5 <- rnorm(6253, 20, 13)\ner <- rnorm(6253, 0, 1)\ny <- .3*x1 - .2*x2 + .4*x3 + er\n\nsim0 <- tibble(y, x1, x2, x3, x4, x5)\n\nsimmod0 <- lm(y ~ x1 + x2 + x3 + x4 + x5, data = sim0)\n\nsummary(simmod0) # appears on next slide\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x1 + x2 + x3 + x4 + x5, data = sim0)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9870 -0.6701 -0.0033  0.6728  3.8474 \n\nCoefficients:\n              Estimate Std. Error  t value Pr(>|t|)    \n(Intercept)  0.0557756  0.0657325    0.849   0.3962    \nx1           0.2968639  0.0025250  117.568   <2e-16 ***\nx2          -0.1993564  0.0010326 -193.059   <2e-16 ***\nx3           0.4021749  0.0012467  322.590   <2e-16 ***\nx4          -0.0001461  0.0008526   -0.171   0.8640    \nx5          -0.0016026  0.0009592   -1.671   0.0948 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9914 on 6247 degrees of freedom\nMultiple R-squared:  0.9621,\tAdjusted R-squared:  0.9621 \nF-statistic: 3.173e+04 on 5 and 6247 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\nTidy summary of the large model:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(model1, conf.int = TRUE, conf.level = 0.90) %>%\n  select(term, estimate, std.error, conf.low, conf.high) %>%\n  knitr::kable(digits = 3)\n```\n\n::: {.cell-output-display}\n\n\n|term                           | estimate| std.error| conf.low| conf.high|\n|:------------------------------|--------:|---------:|--------:|---------:|\n|(Intercept)                    |    0.053|     0.002|    0.049|     0.057|\n|alq121Nearly Every Day         |   -0.007|     0.002|   -0.010|    -0.004|\n|alq1212-4 times/week           |   -0.006|     0.001|   -0.009|    -0.004|\n|alq1212-4 times/month          |   -0.005|     0.001|   -0.007|    -0.003|\n|alq1217-12 times/year          |   -0.004|     0.001|   -0.007|    -0.002|\n|alq1211-6 times/year           |   -0.004|     0.001|   -0.006|    -0.001|\n|ridageyr                       |    0.000|     0.000|    0.000|     0.000|\n|sexfemale                      |    0.019|     0.001|    0.017|     0.020|\n|ridreth3Non-Hispanic White     |    0.007|     0.001|    0.005|     0.009|\n|ridreth3Non-Hispanic Black     |    0.015|     0.001|    0.013|     0.017|\n|ridreth3Non-Hispanic Asian     |    0.004|     0.002|    0.001|     0.007|\n|ridreth3Other Race/Multiracial |    0.008|     0.002|    0.004|     0.011|\n|dmdeduc2HS Grad                |   -0.002|     0.001|   -0.005|     0.000|\n|dmdeduc2Some College           |   -0.003|     0.001|   -0.005|    -0.001|\n|dmdeduc2College Grad           |   -0.002|     0.001|   -0.005|     0.000|\n|dmdeduc27                      |   -0.015|     0.028|   -0.061|     0.032|\n|dmdeduc29                      |    0.006|     0.014|   -0.017|     0.029|\n\n\n:::\n:::\n\n\n\n\nSimply by visually inspecting the coefficients of the ideal model and comparing them to the large and small model, it appears that the coefficients for x4 and x5 are on similar orders of magnitude to those of the large and small model for inverse ALT outcomes, but the variables, x1, x2, and x3 that predict the behavior of y well all have much larger coefficients.\n\n## Assessing Assumptions\n\nTo assess the assumptions of linearity, constant variance, and normality, I constructed residual plots of the ideal model as well as the large and small model.\n\n### Residual plots for ideal model\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nplot(simmod0)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\n\n\n### Residual plots for large model\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nplot(model1)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: not plotting observations with leverage one:\n  2807\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\n\n\nFor the large model, based on the results of the residuals plot in the top left, it appears that the large model parameters do not meet the assumptions of constant variance, since there appears to be a slight widening shape in the residuals plot. The assumptions of normality and linearity are also not met because of the large upward curve at larger values on the Q-Q plot.\n\n### Residual plots for small model\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(2,2))\nplot(model2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-39-1.png){width=672}\n:::\n:::\n\n\n\n\nFor the small model, based on the results of the residuals plot in the top left, it appears that the small model parameters may meet the assumptions of constant variance, since there appears to be a relatively constant range in the residuals plot. The assumptions of normality and linearity are not met because of the large upward curve at larger values on the Q-Q plot.\n\n## Comparing the Models\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng1 <- glance(model1) %>% mutate(model = \"Large Model (5 predictors)\")  \ng2 <- glance(model2) %>% mutate(model = \"Small Model (Key predictor\") \ncomp <- bind_rows(g1, g2) \n\ncomp %>% select(model, r.squared, adj.r.squared, AIC, BIC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  model                      r.squared adj.r.squared     AIC     BIC\n  <chr>                          <dbl>         <dbl>   <dbl>   <dbl>\n1 Large Model (5 predictors)    0.140        0.136   -18854. -18739.\n2 Small Model (Key predictor    0.0111       0.00993 -18266. -18222.\n```\n\n\n:::\n:::\n\n\n\n\nBased on the statistical summaries and the residual plots of the data, I think that the most appropriate model would be the larger model with all 5-predictors, since it has a larger R-squared and adjusted R-squared value than the smaller model. However, there are large drawbacks with the larger model as it does not meet the normality, linearity, and constant variance assumptions as shown in the above residual plots.\n\n# Model Validation\n\n## Calculating Prediction Errors\n\n### Large Model (5 predictors)\n\nI applied the large model (model1) to the test data and did back-transformation to obtain the results of the predictions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_invalt_1 <- predict(model1, newdata = test_data)\n\n# Back-transform predictions by applying the exponential function\npred_alt_1 <- 1/(pred_invalt_1)\n\n# Compare the predicted and actual mpg values\nresult_5_pred <- data.frame(\n  Actual = test_data$lbxsatsi,\n  Predicted_Inverse_Alt = pred_invalt_1,\n  Predicted_Original_Alt = pred_alt_1\n)\n```\n:::\n\n\n\n\n### Small Model (Key predictor)\n\nI applied the small model (model2) to the test data and did back-transformation to obtain the results of the predictions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_invalt_2 <- predict(model2, newdata = test_data)\n\n# Back-transform predictions by applying the exponential function\npred_alt_2 <- 1/(pred_invalt_2)\n\n# Compare the predicted and actual mpg values\nresult_key_pred <- data.frame(\n  Actual = test_data$lbxsatsi,\n  Predicted_Inverse_Alt = pred_invalt_2,\n  Predicted_Original_Alt = pred_alt_2\n)\n```\n:::\n\n\n\n\n## Visualizing the Predictions\n\nAfter back-transformation, I constructed two plots to visualize the predictions of the two models with the test data to the actual outcome variable for ALT values. The range of the predicted values is on the X-axis and the range of the observed values is on the Y-axis.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np4 <- ggplot(result_5_pred, aes(x = Predicted_Original_Alt, y = Actual)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n  labs(\n    title = \"Actual vs Predicted ALT (in U/L) for 5-predictors\",\n    subtitle = \"Predictors: Alcohol consumption, age, sex, race/ethnicity, and education\",\n    x = \"Predicted ALT (in U/L)\",\n    y = \"Actual ALT (in U/L)\"\n  )\n\np5 <- ggplot(result_key_pred, aes(x = Predicted_Original_Alt, y = Actual)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n  labs(\n    title = \"Actual vs Predicted ALT (in U/L) for key predictor\",\n    subtitle = \"Key redictor: Alcohol consumption\",\n    x = \"Predicted ALT (in U/L)\",\n    y = \"Actual ALT (in U/L)\"\n  )\n\np4 | p5\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\n\n\nBased on the actual vs. prediction plots, neither the predictions from the 5-predictors model nor from the key predictor model show close similarity to the actual ALT vlalues. However, since the larger model is able to predict the ALT values across a continuum, it does appear to fit the actual data slightly more accurately, and it has a slightly more positive slope than the key predictors model.\n\n## Summarizing the Errors\n\n### Model 1 (5-predictors) Error Calculation\n\nI calculated the summarized errors for the large model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# RMSPE (Root Mean Squared Prediction Error)\nrmspe <- sqrt(mean((test_data$lbxsatsi - pred_invalt_1)^2))\n\n# MAPE (Mean Absolute Prediction Error)\nmape <- mean(abs((test_data$lbxsatsi - pred_invalt_1) / test_data$lbxsatsi)) * 100\n\n# MAE (Maximum Absolute Prediction Error)\nmae <- max(abs(test_data$lbxsatsi - pred_invalt_1))\n\n# validated R^2 (Squared Correlation of Actual and Predicted)\nvalidated_r2 <- cor(test_data$lbxsatsi, pred_invalt_1)^2\n\n# Print the results\ncat(\"RMSPE: \", rmspe, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRMSPE:  29.63277 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"MAPE: \", mape, \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMAPE:  99.63035 %\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"MAE: \", mae, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMAE:  337.9541 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Validated R^2: \", validated_r2, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nValidated R^2:  0.05305055 \n```\n\n\n:::\n:::\n\n\n\n\n### Model 2 (Key predictor) Error Calculation\n\nI calculated the summarized errors for the small model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# RMSPE (Root Mean Squared Prediction Error)\nrmspe <- sqrt(mean((test_data$lbxsatsi - pred_invalt_2)^2))\n\n# MAPE (Mean Absolute Prediction Error)\nmape <- mean(abs((test_data$lbxsatsi - pred_invalt_2) / test_data$lbxsatsi)) * 100\n\n# MAE (Maximum Absolute Prediction Error)\nmae <- max(abs(test_data$lbxsatsi - pred_invalt_2))\n\n# validated R^2 (Squared Correlation of Actual and Predicted)\nvalidated_r2 <- cor(test_data$lbxsatsi, pred_invalt_2)^2\n\n# Print the results\ncat(\"RMSPE: \", rmspe, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRMSPE:  29.63114 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"MAPE: \", mape, \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMAPE:  99.64008 %\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"MAE: \", mae, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMAE:  337.9464 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Validated R^2: \", validated_r2, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nValidated R^2:  0.009078254 \n```\n\n\n:::\n:::\n\n\n\n\n### Table of Summarized Errors\n\nFinally, I constructed a table of the error calculations.\n\n|       Model        | RMSPE  |  MAPE  |  MAE   | Validated R\\^2 |\n|:------------------:|:------:|:------:|:------:|:--------------:|\n|  Model 1 (5-Pred)  | 29.633 | 99.63% | 337.95 |     0.053      |\n| Model 2 (Key Pred) | 29.631 | 99.64% | 337.95 |     0.009      |\n\n## Comparing the Models\n\nBased on the previous two sections with the visualized predictions and the calculated errors, I still prefer the larger model with five predictors. From the visualization, it appears to have a larger positive slope, which would mean that, while it does not closely approximate the ALT outcome, it does approximate ALT somewhat better than the key predictor model. Given the calculation of the summarizing errors, the RMSPE, MAPE, and MAE are all very similar for both models, indicating that both models have almost the same magnitude of error, average relative error as a percentage of actual values, and largest individual prediction errors. Therefore, my conclusion is based on the validated R-squared from the error calculations, and the larger model has a much higher validated R-squared than the smaller model.\n\n# Discussion\n\n## Chosen Model\n\nThe model I have chosen is the larger model with the five predictors: Alcohol Consumption, Age, Sex, Race/Ethnicity, and Education.\n\n## Answering My Question\n\nMy initial question for this research project was whether the alanine aminotransferase levels (ALT) of participants in the NHANES data set could be accurately modeled by the frequency of alcohol consumption of these participants. Given the results of my two models and that the model with five predictors was a better fit for the ALT outcome, rather than the model with the single, key predictor of alcohol consumption, I conclude that frequency of alcohol consumption alone is not an adequate predictor for ALT outcomes in is population of NHANES participants. This conclusion is limited because the ALT outcome variable was heavily skewed at the beginning of data analysis. This made proper analytical techniques difficult because of the skewness of the data and a lack of interpretable transformations to be applied to the distribution of ALT. While alcohol consumption may be related to ALT levels, it would require more nuanced statistical analysis to determine the relationship between these two variables.\n\n## Next Steps\n\nSince alcohol consumption causes liver damage and liver damage results in an elevated ALT, a logical next step for this analysis would be to restrict analysis of the ALT levels to a group of NHANES participants who have documented liver disease or cirrhosis. In this subset of participants, the effect of ALT may be easier to tease out.\n\n## Reflection\n\nIf I had realized how skewed the data for the ALT outcome variable was and how many high outliers there were in the data, I would have either picked a different variable to analyze, or I would have restricted the ALT values that I was analyzing. I could have asked a different question, such as, does alcohol consumption model levels of ALT in the blood in NHANES participant who are at a low risk for liver damage (i.e.: have a lower ALT value). With this question, I could have restricted the ALT values to the normal physiological range of 7-55U/L. This restriction would have resulted in an outcome variable that had a distribution that was more normally distributed, and therefore it would have been easier to model with various predictors.\n\n# Session Information\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxfun::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sonoma 14.6.1\n\nLocale: en_US.UTF-8 / en_US.UTF-8 / en_US.UTF-8 / C / en_US.UTF-8 / en_US.UTF-8\n\nPackage version:\n  abind_1.4-5           askpass_1.2.0         backports_1.5.0      \n  base64enc_0.1-3       bayestestR_0.14.0     bit_4.0.5            \n  bit64_4.0.5           blob_1.2.4            boot_1.3.30          \n  broom_1.0.6           broom.mixed_0.2.9.5   bslib_0.8.0          \n  cachem_1.1.0          callr_3.7.6           car_3.1-2            \n  carData_3.0-5         cellranger_1.1.0      checkmate_2.3.2      \n  cli_3.6.3             clipr_0.8.0           cluster_2.1.6        \n  coda_0.19.4.1         codetools_0.2.20      colorspace_2.1-1     \n  commonmark_1.9.1      compiler_4.4.1        conflicted_1.2.0     \n  cowplot_1.1.3         cpp11_0.5.0           crayon_1.5.3         \n  curl_6.0.1            data.table_1.16.0     datawizard_0.12.3    \n  DBI_1.2.3             dbplyr_2.5.0          Deriv_4.1.3          \n  digest_0.6.37         doBy_4.6.22           dplyr_1.1.4          \n  dtplyr_1.3.1          equatiomatic_0.3.3    evaluate_0.24.0      \n  fansi_1.0.6           farver_2.1.2          fastmap_1.2.0        \n  fontawesome_0.5.2     forcats_1.0.0         foreign_0.8-87       \n  Formula_1.2-5         fs_1.6.4              furrr_0.3.1          \n  future_1.34.0         gargle_1.5.2          generics_0.1.3       \n  ggplot2_3.5.1         globals_0.16.3        glue_1.7.0           \n  googledrive_2.1.1     googlesheets4_1.1.1   graphics_4.4.1       \n  grDevices_4.4.1       grid_4.4.1            gridExtra_2.3        \n  gtable_0.3.5          haven_2.5.4           highr_0.11           \n  Hmisc_5.1-3           hms_1.1.3             htmlTable_2.4.3      \n  htmltools_0.5.8.1     htmlwidgets_1.6.4     httpuv_1.6.15        \n  httr_1.4.7            ids_1.0.1             insight_0.20.4       \n  isoband_0.2.7         janitor_2.2.0         jquerylib_0.1.4      \n  jsonlite_1.8.8        knitr_1.48            labeling_0.4.3       \n  later_1.3.2           lattice_0.22.6        lifecycle_1.0.4      \n  listenv_0.9.1         lme4_1.1.35.5         lubridate_1.9.3      \n  magrittr_2.0.3        MASS_7.3.61           Matrix_1.7.0         \n  MatrixModels_0.5.3    memoise_2.0.1         methods_4.4.1        \n  mgcv_1.9.1            microbenchmark_1.4.10 mime_0.12            \n  minqa_1.2.8           modelr_0.1.11         modelsummary_2.2.0   \n  munsell_0.5.1         naniar_1.1.0          nlme_3.1.166         \n  nloptr_2.1.1          nnet_7.3-19           norm_1.0.11.1        \n  numDeriv_2016.8.1.1   openssl_2.2.1         parallel_4.4.1       \n  parallelly_1.38.0     parameters_0.22.2     patchwork_1.2.0      \n  pbkrtest_0.5.3        performance_0.12.3    pillar_1.9.0         \n  pkgconfig_2.0.3       plyr_1.8.9            prettyunits_1.2.0    \n  processx_3.8.4        progress_1.2.3        promises_1.3.0       \n  ps_1.7.7              purrr_1.0.2           pwr_1.3-0            \n  quantreg_5.98         R6_2.5.1              ragg_1.3.2           \n  rappdirs_0.3.3        RColorBrewer_1.1.3    Rcpp_1.0.13          \n  RcppEigen_0.3.4.0.2   readr_2.1.5           readxl_1.4.3         \n  rematch_2.0.0         rematch2_2.1.2        reprex_2.1.1         \n  rlang_1.1.4           rmarkdown_2.28        rpart_4.1.23         \n  rstudioapi_0.16.0     rvest_1.0.4           sass_0.4.9           \n  scales_1.3.0          selectr_0.4.2         shiny_1.9.1          \n  snakecase_0.11.1      sourcetools_0.1.7.1   SparseM_1.84.2       \n  splines_4.4.1         stats_4.4.1           stringi_1.8.4        \n  stringr_1.5.1         survival_3.7.0        sys_3.4.2            \n  systemfonts_1.1.0     tables_0.9.31         textshaping_0.4.0    \n  tibble_3.2.1          tidyr_1.3.1           tidyselect_1.2.1     \n  tidyverse_2.0.0       timechange_0.3.0      tinytable_0.4.0      \n  tinytex_0.52          tools_4.4.1           tzdb_0.4.0           \n  UpSetR_1.4.0          utf8_1.2.4            utils_4.4.1          \n  uuid_1.2.1            vctrs_0.6.5           viridis_0.6.5        \n  viridisLite_0.4.2     visdat_0.6.0          vroom_1.6.5          \n  withr_3.0.1           xfun_0.47             xml2_1.3.6           \n  xtable_1.8-4          yaml_2.3.10          \n```\n\n\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}